{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbd = pd.read_csv(\"D:/dataset/imdb_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader\n",
    "valence Aware Dictionary and sentiment reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i love india')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  we must calculate the normalization because u must know what is the polarity of the word between -1 to +1\n",
    "\n",
    "score = 3.2\n",
    "alpha = 15\n",
    "\n",
    "Normalization = score/(np.sqrt(np.square(score))+aplha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369499429264264"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.2/(np.sqrt(3.2*3.2+15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  polarity percentage calculation(positive,negative,neutral)\n",
    "\n",
    "Here the values are,\n",
    "         Pos = 3.2\n",
    "         Neg = 0\n",
    "         Neutral = ?\n",
    "\n",
    "therefore we must add 1 to neutral and to make a proper calculation even the positive will be taken as +1\n",
    "\n",
    "therefore,\n",
    "          * Pos = 3.2+1\n",
    "          * Neg = 0\n",
    "          * Neutral = 1\n",
    "          \n",
    "      -- % of pos = no. of positive/ total no.of scores\n",
    "      -- % of neg = no. of negative/ total no.of scores\n",
    "      -- % of neutral = no. of neutral/ total no.of scores\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Capital letters -> pos,neg\n",
    "2. emoji -> punctuation\n",
    "3. negate words\n",
    "4. boosting words\n",
    "5. punctuate -> !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.374, 'neu': 0.202, 'pos': 0.424, 'compound': 0.128}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i love india i hate apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i love india i hate apple')['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    compound = sentiment.polarity_scores(text)['compound']\n",
    "    if compound < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbd['sentiment_vader'] = imbd['review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7767379679144385"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(imbd['sentiment'],imbd['sentiment_vader'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC Modelling\n",
    "(not in syllabus)\n",
    "\n",
    "    --LSA\n",
    "    --Matrix Factorisation\n",
    "    --LDA (Latent Dirichlet Allocation) -- latent means hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. here we will have topic -> document\n",
    "2. or document -> term\n",
    "3. or topic -> term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application:\n",
    "\n",
    "1. what kind of topics is used in the article or transcript, product catlog\n",
    "2. text clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. each term will be given an id and wherever this term comes there the id will be given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/54/ee/c1f685caa83ee9b8f54573b51648af61b01377bcc5981a18704f5247cce7/gensim-3.7.1-cp36-cp36m-win_amd64.whl (24.1MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from gensim) (1.14.2)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from gensim) (1.1.0)\n",
      "Collecting smart-open>=1.7.0 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/c8/de7dcf34d4b5f2ae94fe1055e0d6418fb97a63c9dc3428edd264704983a2/smart_open-1.8.0.tar.gz (40kB)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.48.0)\n",
      "Collecting bz2file (from smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.18.4)\n",
      "Collecting boto3 (from smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/fe/84f9d30273a58684d0db5ea506803ff762c3e2641546c68925a63b2fd600/boto3-1.9.99-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2018.4.16)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/de/5737f602e22073ecbded7a0c590707085e154e32b68d86545dcc31004c02/s3transfer-0.2.0-py2.py3-none-any.whl (69kB)\n",
      "Collecting botocore<1.13.0,>=1.12.99 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/8e/8ee2bdc57d68de0036bdcd5e9f649f758a8e5c39a4c92fbe166a0307238f/botocore-1.12.99-py2.py3-none-any.whl (5.3MB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.99->boto3->smart-open>=1.7.0->gensim) (2.7.3)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.99->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open: started\n",
      "  Running setup.py bdist_wheel for smart-open: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Administrator\\AppData\\Local\\pip\\Cache\\wheels\\f7\\a6\\ff\\9ab5842c14e50e95a06a4675b0b4a689c9cab6064dac2b01d0\n",
      "  Running setup.py bdist_wheel for bz2file: started\n",
      "  Running setup.py bdist_wheel for bz2file: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Administrator\\AppData\\Local\\pip\\Cache\\wheels\\81\\75\\d6\\e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: bz2file, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.9.99 botocore-1.12.99 bz2file-0.98 gensim-3.7.1 jmespath-0.9.3 s3transfer-0.2.0 smart-open-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 2.5.1 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = pd.read_csv(\"D:/dataset/amazon_reviews_big.csv\")\n",
    "amazon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000HDJXNA</td>\n",
       "      <td>1</td>\n",
       "      <td>What I recieved is not what is pictured here O...</td>\n",
       "      <td>12 26, 2012</td>\n",
       "      <td>A29YXBFTD7QUP3</td>\n",
       "      <td>HHA</td>\n",
       "      <td>Buyer be ware</td>\n",
       "      <td>1.356480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006KKS7XQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent unit and a pretty simple install usi...</td>\n",
       "      <td>09 20, 2013</td>\n",
       "      <td>A3IMTXFYD7CGDN</td>\n",
       "      <td>Peter W. George \"soyflakeman\"</td>\n",
       "      <td>high quality without high price</td>\n",
       "      <td>1.379635e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002NP8XJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm enjoying this keyboard, I'm getting anothe...</td>\n",
       "      <td>08 31, 2010</td>\n",
       "      <td>AXNOW20FQKHVW</td>\n",
       "      <td>B. Hayashi</td>\n",
       "      <td>Superb keyboard + solution for slow wake up an...</td>\n",
       "      <td>1.283213e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000HDJXNA        1  What I recieved is not what is pictured here O...   \n",
       "1  B006KKS7XQ        5  Excellent unit and a pretty simple install usi...   \n",
       "2  B002NP8XJ0        5  I'm enjoying this keyboard, I'm getting anothe...   \n",
       "\n",
       "    reviewTime      reviewerID                   reviewerName  \\\n",
       "0  12 26, 2012  A29YXBFTD7QUP3                            HHA   \n",
       "1  09 20, 2013  A3IMTXFYD7CGDN  Peter W. George \"soyflakeman\"   \n",
       "2  08 31, 2010   AXNOW20FQKHVW                     B. Hayashi   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                      Buyer be ware    1.356480e+09  \n",
       "1                    high quality without high price    1.379635e+09  \n",
       "2  Superb keyboard + solution for slow wake up an...    1.283213e+09  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = amazon['reviewText'].fillna(\"\").str.lower()\n",
    "docs = docs.str.replace('[^a-z ]','')\n",
    "\n",
    "docs_clean = []\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "#stopwords.extend(['']) # the punction '' will be taken from the words--- where it is just telling that to extend or include to the stopwords even the puntuation ''\n",
    "\n",
    "for doc in docs: \n",
    "    words=doc.split(\" \")\n",
    "    words_clean = [stemmer.stem(word) for word in words if word not in stopwords]\n",
    "    words_clean = [word for word in words_clean if word not in stopwords]\n",
    "    docs_clean.append(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(zip(dictionary.keys(),dictionary.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.doc2bow(docs_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_bow = []\n",
    "for doc in docs_clean:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 5),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 3),\n",
       " (12, 2),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 2),\n",
       " (20, 1),\n",
       " (21, 2),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 2),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 2),\n",
       " (37, 2),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_bow[0])# no of terms in 1st document(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(docs_bow,id2word=dictionary,num_topics=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.7066013), (3, 0.2856489)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_document_topics(docs_bow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "document is a collection of topics and topics are the collection of terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2topic = pd.DataFrame(lda_model.get_document_topics(docs_bow[0]),columns=['topic_no','prob'])\n",
    "doc2topic.sort_values('prob',ascending=False).iloc[0]['topic_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for bow in docs_bow:\n",
    "    doc2topic = pd.DataFrame(lda_model.get_document_topics(bow),columns=['topic_no','prob'])\n",
    "    topic = doc2topic.sort_values('prob',ascending=False).iloc[0]['topic_no']\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.058*\"\" + 0.021*\"camera\" + 0.016*\"use\" + 0.014*\"batteri\" + 0.009*\"len\" + 0.008*\"one\" + 0.008*\"great\" + 0.007*\"screen\" + 0.007*\"get\" + 0.007*\"good\"'),\n",
       " (1,\n",
       "  '0.075*\"\" + 0.014*\"work\" + 0.013*\"use\" + 0.009*\"one\" + 0.007*\"get\" + 0.006*\"drive\" + 0.006*\"tv\" + 0.006*\"devic\" + 0.006*\"cabl\" + 0.006*\"connect\"'),\n",
       " (2,\n",
       "  '0.043*\"\" + 0.023*\"case\" + 0.013*\"use\" + 0.011*\"fit\" + 0.010*\"like\" + 0.010*\"keyboard\" + 0.009*\"one\" + 0.008*\"well\" + 0.008*\"ipad\" + 0.008*\"mous\"'),\n",
       " (3,\n",
       "  '0.049*\"\" + 0.023*\"sound\" + 0.013*\"speaker\" + 0.012*\"good\" + 0.011*\"qualiti\" + 0.010*\"use\" + 0.010*\"great\" + 0.009*\"headphon\" + 0.008*\"like\" + 0.007*\"price\"')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = pd.read_csv(\"D:/dataset/abcnews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = abc['headline_text'].str.lower()\n",
    "doc = doc.replace('[^a-b ]',\"\")\n",
    "\n",
    "doc_clean = []\n",
    "\n",
    "for docu in doc:\n",
    "    text = docu.split(\" \")\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords]\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    doc_clean.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aba', 'decid', 'commun', 'broadcast', 'licenc']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bow = []\n",
    "for doc in doc_clean:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    doc_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(389, 1), (2373, 1), (5797, 1), (7546, 1), (8663, 1)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_bow[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(doc_bow,id2word=dictionary,num_topics=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for bow in doc_bow:\n",
    "    doc2topic = pd.DataFrame(lda_model.get_document_topics(bow),columns=['topic_no','prob'])\n",
    "    topic = doc2topic.sort_values('prob',ascending=False).iloc[0]['topic_no']\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
